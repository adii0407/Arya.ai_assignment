{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arya.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics as mt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('C:\\\\Data\\\\Internship')\n",
    "\n",
    "train_data= pd.read_csv('training_set.csv')\n",
    "test_data= pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "      <th>X51</th>\n",
       "      <th>X52</th>\n",
       "      <th>X53</th>\n",
       "      <th>X54</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.342</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.200</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>16.304</td>\n",
       "      <td>148</td>\n",
       "      <td>375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.440</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.46</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.338</td>\n",
       "      <td>123</td>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3905</th>\n",
       "      <td>3905</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.714</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>3906</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>3907</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.247</td>\n",
       "      <td>5</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>3908</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.857</td>\n",
       "      <td>25</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>3909</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.116</td>\n",
       "      <td>9.560</td>\n",
       "      <td>259</td>\n",
       "      <td>717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3910 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    X1    X2    X3     X4    X5    X6    X7    X8    X9  ...  \\\n",
       "0              0  0.00  0.00  4.34   0.00  0.00  0.00  0.00  0.00  0.00  ...   \n",
       "1              1  0.00  0.56  0.56   0.00  1.12  0.56  2.25  0.00  0.00  ...   \n",
       "2              2  0.00  0.00  0.00   0.00  0.00  0.00  0.00  0.00  0.00  ...   \n",
       "3              3  0.64  0.00  0.64   0.00  1.93  0.00  0.00  0.00  0.00  ...   \n",
       "4              4  0.58  0.00  0.00  35.46  0.58  0.00  0.58  0.58  0.00  ...   \n",
       "...          ...   ...   ...   ...    ...   ...   ...   ...   ...   ...  ...   \n",
       "3905        3905  0.00  0.00  0.00   0.00  0.00  0.00  0.00  0.00  0.00  ...   \n",
       "3906        3906  0.00  0.00  0.00   0.00  0.00  0.00  0.00  0.00  0.00  ...   \n",
       "3907        3907  0.12  0.00  0.12   0.00  0.00  0.25  0.00  0.00  0.00  ...   \n",
       "3908        3908  0.00  0.00  0.00   0.00  0.00  0.00  0.00  3.12  0.00  ...   \n",
       "3909        3909  0.96  0.00  0.48   0.00  0.00  0.96  0.00  0.00  0.48  ...   \n",
       "\n",
       "      X49    X50  X51    X52    X53    X54     X55  X56  X57  Y  \n",
       "0     0.0  0.000  0.0  1.342  0.000  0.000   1.200    2   12  0  \n",
       "1     0.0  0.083  0.0  0.503  0.000  0.083  16.304  148  375  1  \n",
       "2     0.0  0.000  0.0  0.000  0.000  0.000   1.000    1    5  0  \n",
       "3     0.0  0.000  0.0  0.462  0.370  0.000   2.440   22  122  1  \n",
       "4     0.0  0.000  0.0  0.239  0.239  0.000   3.338  123  207  1  \n",
       "...   ...    ...  ...    ...    ...    ...     ...  ...  ... ..  \n",
       "3905  0.0  0.000  0.0  0.000  0.000  0.000   1.714    4   12  0  \n",
       "3906  0.0  0.000  0.0  0.000  0.000  0.000   2.000    3    4  0  \n",
       "3907  0.0  0.093  0.0  0.023  0.000  0.000   1.247    5  131  0  \n",
       "3908  0.0  0.198  0.0  0.198  0.198  0.000   3.857   25   81  1  \n",
       "3909  0.0  0.818  0.0  0.175  0.467  0.116   9.560  259  717  1  \n",
       "\n",
       "[3910 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for missing values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "X1            0\n",
       "X2            0\n",
       "X3            0\n",
       "X4            0\n",
       "X5            0\n",
       "X6            0\n",
       "X7            0\n",
       "X8            0\n",
       "X9            0\n",
       "X10           0\n",
       "X11           0\n",
       "X12           0\n",
       "X13           0\n",
       "X14           0\n",
       "X15           0\n",
       "X16           0\n",
       "X17           0\n",
       "X18           0\n",
       "X19           0\n",
       "X20           0\n",
       "X21           0\n",
       "X22           0\n",
       "X23           0\n",
       "X24           0\n",
       "X25           0\n",
       "X26           0\n",
       "X27           0\n",
       "X28           0\n",
       "X29           0\n",
       "X30           0\n",
       "X31           0\n",
       "X32           0\n",
       "X33           0\n",
       "X34           0\n",
       "X35           0\n",
       "X36           0\n",
       "X37           0\n",
       "X38           0\n",
       "X39           0\n",
       "X40           0\n",
       "X41           0\n",
       "X42           0\n",
       "X43           0\n",
       "X44           0\n",
       "X45           0\n",
       "X46           0\n",
       "X47           0\n",
       "X48           0\n",
       "X49           0\n",
       "X50           0\n",
       "X51           0\n",
       "X52           0\n",
       "X53           0\n",
       "X54           0\n",
       "X55           0\n",
       "X56           0\n",
       "X57           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()\n",
    "\n",
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the distribution of the target variable Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.607673\n",
       "1    0.392327\n",
       "Name: Y, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Y'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 60% 0s and only 40% in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "      <th>X51</th>\n",
       "      <th>X52</th>\n",
       "      <th>X53</th>\n",
       "      <th>X54</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "      <td>3910.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1954.500000</td>\n",
       "      <td>0.102990</td>\n",
       "      <td>0.206419</td>\n",
       "      <td>0.284419</td>\n",
       "      <td>0.062074</td>\n",
       "      <td>0.311309</td>\n",
       "      <td>0.095974</td>\n",
       "      <td>0.112320</td>\n",
       "      <td>0.106041</td>\n",
       "      <td>0.091146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037493</td>\n",
       "      <td>0.139252</td>\n",
       "      <td>0.015876</td>\n",
       "      <td>0.272971</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.043828</td>\n",
       "      <td>5.047150</td>\n",
       "      <td>52.338107</td>\n",
       "      <td>283.059079</td>\n",
       "      <td>0.392327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1128.864105</td>\n",
       "      <td>0.296322</td>\n",
       "      <td>1.253828</td>\n",
       "      <td>0.504352</td>\n",
       "      <td>1.369361</td>\n",
       "      <td>0.656195</td>\n",
       "      <td>0.261455</td>\n",
       "      <td>0.389516</td>\n",
       "      <td>0.398694</td>\n",
       "      <td>0.271417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235054</td>\n",
       "      <td>0.276309</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>0.858634</td>\n",
       "      <td>0.256991</td>\n",
       "      <td>0.452862</td>\n",
       "      <td>31.397035</td>\n",
       "      <td>204.445218</td>\n",
       "      <td>578.339858</td>\n",
       "      <td>0.488331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>977.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.580750</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1954.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.263500</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2931.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317250</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.714000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3909.000000</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>4.540000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>2.777000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>10062.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0           X1           X2           X3           X4  \\\n",
       "count  3910.000000  3910.000000  3910.000000  3910.000000  3910.000000   \n",
       "mean   1954.500000     0.102990     0.206419     0.284419     0.062074   \n",
       "std    1128.864105     0.296322     1.253828     0.504352     1.369361   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%     977.250000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%    1954.500000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%    2931.750000     0.000000     0.000000     0.430000     0.000000   \n",
       "max    3909.000000     4.340000    14.280000     4.540000    42.810000   \n",
       "\n",
       "                X5           X6           X7           X8           X9  ...  \\\n",
       "count  3910.000000  3910.000000  3910.000000  3910.000000  3910.000000  ...   \n",
       "mean      0.311309     0.095974     0.112320     0.106041     0.091146  ...   \n",
       "std       0.656195     0.261455     0.389516     0.398694     0.271417  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.387500     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       9.090000     3.570000     7.270000    11.110000     3.230000  ...   \n",
       "\n",
       "               X49          X50          X51          X52          X53  \\\n",
       "count  3910.000000  3910.000000  3910.000000  3910.000000  3910.000000   \n",
       "mean      0.037493     0.139252     0.015876     0.272971     0.077820   \n",
       "std       0.235054     0.276309     0.083600     0.858634     0.256991   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.066000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.188000     0.000000     0.317250     0.054000   \n",
       "max       4.385000     9.752000     2.777000    32.478000     6.003000   \n",
       "\n",
       "               X54          X55          X56           X57            Y  \n",
       "count  3910.000000  3910.000000  3910.000000   3910.000000  3910.000000  \n",
       "mean      0.043828     5.047150    52.338107    283.059079     0.392327  \n",
       "std       0.452862    31.397035   204.445218    578.339858     0.488331  \n",
       "min       0.000000     1.000000     1.000000      1.000000     0.000000  \n",
       "25%       0.000000     1.580750     6.000000     35.000000     0.000000  \n",
       "50%       0.000000     2.263500    15.000000     94.000000     0.000000  \n",
       "75%       0.000000     3.714000    43.000000    264.000000     1.000000  \n",
       "max      19.829000  1102.500000  9989.000000  10062.000000     1.000000  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "X1            float64\n",
       "X2            float64\n",
       "X3            float64\n",
       "X4            float64\n",
       "X5            float64\n",
       "X6            float64\n",
       "X7            float64\n",
       "X8            float64\n",
       "X9            float64\n",
       "X10           float64\n",
       "X11           float64\n",
       "X12           float64\n",
       "X13           float64\n",
       "X14           float64\n",
       "X15           float64\n",
       "X16           float64\n",
       "X17           float64\n",
       "X18           float64\n",
       "X19           float64\n",
       "X20           float64\n",
       "X21           float64\n",
       "X22           float64\n",
       "X23           float64\n",
       "X24           float64\n",
       "X25           float64\n",
       "X26           float64\n",
       "X27           float64\n",
       "X28           float64\n",
       "X29           float64\n",
       "X30           float64\n",
       "X31           float64\n",
       "X32           float64\n",
       "X33           float64\n",
       "X34           float64\n",
       "X35           float64\n",
       "X36           float64\n",
       "X37           float64\n",
       "X38           float64\n",
       "X39           float64\n",
       "X40           float64\n",
       "X41           float64\n",
       "X42           float64\n",
       "X43           float64\n",
       "X44           float64\n",
       "X45           float64\n",
       "X46           float64\n",
       "X47           float64\n",
       "X48           float64\n",
       "X49           float64\n",
       "X50           float64\n",
       "X51           float64\n",
       "X52           float64\n",
       "X53           float64\n",
       "X54           float64\n",
       "X55           float64\n",
       "X56             int64\n",
       "X57             int64\n",
       "Y               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking co-relation of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.corr().style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= train_data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(['Y'],axis=1)\n",
    "y = train_data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking for Constant features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "var_thres=VarianceThreshold(threshold=0)\n",
    "var_thres.fit(X_train)\n",
    "\n",
    "sum(var_thres.get_support())\n",
    "\n",
    "len(X_train.columns[var_thres.get_support()])\n",
    "\n",
    "constant_columns = [column for column in X_train.columns\n",
    "                    if column not in X_train.columns[var_thres.get_support()]]\n",
    "\n",
    "print(len(constant_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing Corelated Features if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_features = correlation(X_train, 0.8)\n",
    "len(set(corr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X34', 'X40'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_features_test = correlation(X_test, 0.8)\n",
    "len(set(corr_features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X32', 'X34', 'X40'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.drop(corr_features,axis=1)\n",
    "X_test=X_test.drop(corr_features_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.drop('X32',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05133284, 0.06300119, 0.08583042, 0.01100967, 0.08204845,\n",
       "       0.05305306, 0.14600355, 0.08827754, 0.06365283, 0.06483618,\n",
       "       0.07934792, 0.04429275, 0.03817403, 0.02493633, 0.03230376,\n",
       "       0.12914661, 0.06967549, 0.04564042, 0.11689325, 0.06726581,\n",
       "       0.15460313, 0.00809693, 0.11977359, 0.13063468, 0.11590261,\n",
       "       0.08943015, 0.0868368 , 0.03118809, 0.03058933, 0.04935188,\n",
       "       0.02824093, 0.        , 0.02547091, 0.02337064, 0.04436242,\n",
       "       0.        , 0.025634  , 0.01244558, 0.02776411, 0.04618288,\n",
       "       0.00689849, 0.05194497, 0.03173028, 0.00286989, 0.01167781,\n",
       "       0.02644208, 0.06072697, 0.01798853, 0.20282168, 0.18102915,\n",
       "       0.04681676, 0.18676767, 0.20361086, 0.1334231 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the mutual information\n",
    "mutual_info = mutual_info_classif(X_train, y_train)\n",
    "mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X56    0.203611\n",
       "X52    0.202822\n",
       "X55    0.186768\n",
       "X53    0.181029\n",
       "X21    0.154603\n",
       "X7     0.146004\n",
       "X57    0.133423\n",
       "X24    0.130635\n",
       "X16    0.129147\n",
       "X23    0.119774\n",
       "X19    0.116893\n",
       "X25    0.115903\n",
       "X26    0.089430\n",
       "X8     0.088278\n",
       "X27    0.086837\n",
       "X3     0.085830\n",
       "X5     0.082048\n",
       "X11    0.079348\n",
       "X17    0.069675\n",
       "X20    0.067266\n",
       "X10    0.064836\n",
       "X9     0.063653\n",
       "X2     0.063001\n",
       "X50    0.060727\n",
       "X6     0.053053\n",
       "X45    0.051945\n",
       "X1     0.051333\n",
       "X30    0.049352\n",
       "X54    0.046817\n",
       "X43    0.046183\n",
       "X18    0.045640\n",
       "X37    0.044362\n",
       "X12    0.044293\n",
       "X13    0.038174\n",
       "X15    0.032304\n",
       "X46    0.031730\n",
       "X28    0.031188\n",
       "X29    0.030589\n",
       "X31    0.028241\n",
       "X42    0.027764\n",
       "X49    0.026442\n",
       "X39    0.025634\n",
       "X35    0.025471\n",
       "X14    0.024936\n",
       "X36    0.023371\n",
       "X51    0.017989\n",
       "X41    0.012446\n",
       "X48    0.011678\n",
       "X4     0.011010\n",
       "X22    0.008097\n",
       "X44    0.006898\n",
       "X47    0.002870\n",
       "X33    0.000000\n",
       "X38    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X_train.columns\n",
    "mutual_info.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI4AAAHbCAYAAACtENF6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAv9klEQVR4nO3df9Bld10n+PfHbqKiIL9akkqCHTGLk5mViDE46+goLG5IZmycESfUGH4sTsAlIuMwQxc7zlrlrtXLgj+wkEzEaPAHDK4gXaYV2ejoWIKmCTEQ2GiMDTQJSYMobKWKEPLdP+5pc3n8dvo+9zknz3O6X6+qW8+958fnfr7nfM85tz99flRrLQAAAACw0ZdsdwIAAAAA7EwKRwAAAAB0KRwBAAAA0KVwBAAAAECXwhEAAAAAXbu3O4HNeMITntD27t273WkAAAAAnDLe9773fbK1tqc3blaFo7179+bw4cPbnQYAAADAKaOqPnKicS5VAwAAAKBL4QgAAACALoUjAAAAALoUjgAAAADoUjgCAAAAoEvhCAAAAIAuhSMAAAAAuhSOAAAAAOhSOAIAAACgS+EIAAAAgC6FIwAAAAC6FI4AAAAA6FI4AgAAAKBL4QgAAACALoUjAAAAALoUjgAAAADoUjgCAAAAoEvhCAAAAIAuhSMAAAAAunZvdwJbtXf/9StNd+TAZRNnAgAAAHBqccYRAAAAAF2zP+NoCs5iAgAAAHDGEQAAAAAnsFLhqKouqarbqur2qtrfGf+vq+qW4fXHVfXUk81bVY+rqndX1V8Mfx87TpMAAAAAGMNJC0dVtSvJG5I8O8kFSZ5XVRdsmOyvkvzT1to3JPnxJNesMO/+JDe01s5PcsPwGQAAAIAdYpUzji5Ocntr7Y7W2n1J3ppk3/IErbU/bq19evj43iTnrDDvviTXDe+vS/KctVsBAAAAwOhWKRydneRjS5+PDsNO5MVJfnuFeZ/YWrsrSYa/X90LVlVXVtXhqjp87NixFdIFAAAAYAyrFI6qM6x1J6z6ziwKR6/a7Lwn0lq7prV2UWvtoj179mxmVgAAAAC2YJXC0dEk5y59PifJnRsnqqpvSPKmJPtaa59aYd67q+qsYd6zktyzudQBAAAAmNIqhaMbk5xfVedV1RlJLk9ycHmCqnpSkrcnuaK19ucrznswyQuG9y9I8s71mwEAAADA2HafbILW2v1VdVWSdyXZleTa1tqtVfXSYfzVSf5Tkscn+bmqSpL7h8vLuvMOoQ8keVtVvTjJR5M8d+S2AQAAALAFJy0cJUlr7VCSQxuGXb30/geS/MCq8w7DP5XkmZtJFgAAAICHzyqXqgEAAABwGlI4AgAAAKBL4QgAAACALoUjAAAAALoUjgAAAADoUjgCAAAAoEvhCAAAAIAuhSMAAAAAuhSOAAAAAOhSOAIAAACgS+EIAAAAgC6FIwAAAAC6FI4AAAAA6FI4AgAAAKBL4QgAAACALoUjAAAAALoUjgAAAADoUjgCAAAAoEvhCAAAAIAuhSMAAAAAuhSOAAAAAOjavd0JnA727r9+5WmPHLhswkwAAAAAVueMIwAAAAC6FI4AAAAA6FI4AgAAAKBL4QgAAACALoUjAAAAALoUjgAAAADoUjgCAAAAoEvhCAAAAIAuhSMAAAAAuhSOAAAAAOhSOAIAAACga/d2J8B69u6/fqXpjhy4bOJMAAAAgFOVM44AAAAA6FI4AgAAAKBL4QgAAACALoUjAAAAALoUjgAAAADoUjgCAAAAoEvhCAAAAIAuhSMAAAAAulYqHFXVJVV1W1XdXlX7O+O/vqreU1Wfq6pXLg1/SlXdvPT6TFW9Yhj3Y1X18aVxl47WKgAAAAC2bPfJJqiqXUnekORZSY4mubGqDrbWPrQ02V8neXmS5yzP21q7LcmFS3E+nuQdS5P8VGvttVvIHwAAAICJrHLG0cVJbm+t3dFauy/JW5PsW56gtXZPa+3GJJ9/iDjPTPKXrbWPrJ0tAAAAAA+bVQpHZyf52NLno8Owzbo8yVs2DLuqqm6pqmur6rG9marqyqo6XFWHjx07tsbXAgAAALCOVQpH1RnWNvMlVXVGku9O8utLg9+Y5MlZXMp2V5LX9eZtrV3TWruotXbRnj17NvO1AAAAAGzBKoWjo0nOXfp8TpI7N/k9z05yU2vt7uMDWmt3t9a+0Fp7IMnPZ3FJHAAAAAA7xCqFoxuTnF9V5w1nDl2e5OAmv+d52XCZWlWdtfTxe5J8cJMxAQAAAJjQSZ+q1lq7v6quSvKuJLuSXNtau7WqXjqMv7qqzkxyOMmjkzxQVa9IckFr7TNV9cgsnsj2kg2hX1NVF2Zx2duRzngAAAAAttFJC0dJ0lo7lOTQhmFXL73/RBaXsPXmvTfJ4zvDr9hUpgAAAAA8rFa5VA0AAACA05DCEQAAAABdCkcAAAAAdCkcAQAAANClcAQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAECXwhEAAAAAXQpHAAAAAHQpHAEAAADQpXAEAAAAQJfCEQAAAABdCkcAAAAAdCkcAQAAANClcAQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAECXwhEAAAAAXQpHAAAAAHQpHAEAAADQpXAEAAAAQJfCEQAAAABdCkcAAAAAdCkcAQAAANClcAQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAECXwhEAAAAAXQpHAAAAAHQpHAEAAADQtXu7E2Dn2Lv/+pWmO3LgsokzAQAAAHYCZxwBAAAA0KVwBAAAAECXwhEAAAAAXQpHAAAAAHQpHAEAAADQtVLhqKouqarbqur2qtrfGf/1VfWeqvpcVb1yw7gjVfWBqrq5qg4vDX9cVb27qv5i+PvYrTcHAAAAgLGctHBUVbuSvCHJs5NckOR5VXXBhsn+OsnLk7z2BGG+s7V2YWvtoqVh+5Pc0Fo7P8kNw2cAAAAAdohVzji6OMntrbU7Wmv3JXlrkn3LE7TW7mmt3Zjk85v47n1JrhveX5fkOZuYFwAAAICJrVI4OjvJx5Y+Hx2Graol+d2qel9VXbk0/ImttbuSZPj71b2Zq+rKqjpcVYePHTu2ia8FAAAAYCtWKRxVZ1jbxHd8a2vtaVlc6vayqvr2Tcyb1to1rbWLWmsX7dmzZzOzAgAAALAFqxSOjiY5d+nzOUnuXPULWmt3Dn/vSfKOLC59S5K7q+qsJBn+3rNqTAAAAACmt0rh6MYk51fVeVV1RpLLkxxcJXhVfUVVPer4+yTfleSDw+iDSV4wvH9BknduJnEAAAAAprX7ZBO01u6vqquSvCvJriTXttZuraqXDuOvrqozkxxO8ugkD1TVK7J4AtsTkryjqo5/16+11n5nCH0gyduq6sVJPprkuaO2DAAAAIAtOWnhKElaa4eSHNow7Oql95/I4hK2jT6T5KkniPmpJM9cOVMAAAAAHlarXKoGAAAAwGlI4QgAAACArpUuVYN17N1//crTHjlw2YSZAAAAAOtwxhEAAAAAXQpHAAAAAHQpHAEAAADQpXAEAAAAQJfCEQAAAABdCkcAAAAAdCkcAQAAANClcAQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAECXwhEAAAAAXQpHAAAAAHQpHAEAAADQpXAEAAAAQJfCEQAAAABdCkcAAAAAdCkcAQAAANClcAQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAECXwhEAAAAAXbu3OwHYjL37r19puiMHLps4EwAAADj1OeMIAAAAgC6FIwAAAAC6FI4AAAAA6FI4AgAAAKDLzbE57bnhNgAAAPQ54wgAAACALoUjAAAAALpcqgYjW/XSt8TlbwAAAOxszjgCAAAAoEvhCAAAAIAuhSMAAAAAuhSOAAAAAOhSOAIAAACga6XCUVVdUlW3VdXtVbW/M/7rq+o9VfW5qnrl0vBzq+r3q+rDVXVrVf3w0rgfq6qPV9XNw+vScZoEAAAAwBh2n2yCqtqV5A1JnpXkaJIbq+pga+1DS5P9dZKXJ3nOhtnvT/LvWms3VdWjkryvqt69NO9PtdZeu9VGAAAAADC+Vc44ujjJ7a21O1pr9yV5a5J9yxO01u5prd2Y5PMbht/VWrtpeP/ZJB9OcvYomQMAAAAwqVUKR2cn+djS56NZo/hTVXuTfGOSP1kafFVV3VJV11bVY08w35VVdbiqDh87dmyzXwsAAADAmlYpHFVnWNvMl1TVVyb5jSSvaK19Zhj8xiRPTnJhkruSvK43b2vtmtbaRa21i/bs2bOZrwUAAABgC1YpHB1Ncu7S53OS3LnqF1TVI7IoGv1qa+3tx4e31u5urX2htfZAkp/P4pI4AAAAAHaIVQpHNyY5v6rOq6ozklye5OAqwauqkvxCkg+31n5yw7izlj5+T5IPrpYyAAAAAA+Hkz5VrbV2f1VdleRdSXYluba1dmtVvXQYf3VVnZnkcJJHJ3mgql6R5IIk35DkiiQfqKqbh5Cvbq0dSvKaqrowi8vejiR5yYjtAgAAAGCLTlo4SpKh0HNow7Crl95/IotL2Db6o/TvkZTW2hWrpwkAAADAw22VS9UAAAAAOA0pHAEAAADQpXAEAAAAQJfCEQAAAABdCkcAAAAAdK30VDVge+3df/1K0x05cNnEmQAAAHA6ccYRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAECXm2PDacoNtwEAADgZZxwBAAAA0OWMI2AUq57BlDiLCQAAYC6ccQQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAECXwhEAAAAAXQpHAAAAAHQpHAEAAADQpXAEAAAAQJfCEQAAAABdCkcAAAAAdCkcAQAAANClcAQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAECXwhEAAAAAXQpHAAAAAHQpHAEAAADQpXAEAAAAQJfCEQAAAABdCkcAAAAAdCkcAQAAANClcAQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAEDXSoWjqrqkqm6rqturan9n/NdX1Xuq6nNV9cpV5q2qx1XVu6vqL4a/j916cwAAAAAYy0kLR1W1K8kbkjw7yQVJnldVF2yY7K+TvDzJazcx7/4kN7TWzk9yw/AZAAAAgB1ilTOOLk5ye2vtjtbafUnemmTf8gSttXtaazcm+fwm5t2X5Lrh/XVJnrNeEwAAAACYwiqFo7OTfGzp89Fh2Coeat4nttbuSpLh71f3AlTVlVV1uKoOHzt2bMWvBQAAAGCrVikcVWdYWzH+VuZdTNzaNa21i1prF+3Zs2czswIAAACwBasUjo4mOXfp8zlJ7lwx/kPNe3dVnZUkw997VowJAAAAwMNglcLRjUnOr6rzquqMJJcnObhi/Iea92CSFwzvX5DknaunDQAAAMDUdp9sgtba/VV1VZJ3JdmV5NrW2q1V9dJh/NVVdWaSw0keneSBqnpFkgtaa5/pzTuEPpDkbVX14iQfTfLckdsGAAAAwBactHCUJK21Q0kObRh29dL7T2RxGdpK8w7DP5XkmZtJFgAAAICHzyqXqgEAAABwGlI4AgAAAKBL4QgAAACALoUjAAAAALoUjgAAAADoUjgCAAAAoEvhCAAAAIAuhSMAAAAAuhSOAAAAAOhSOAIAAACgS+EIAAAAgC6FIwAAAAC6FI4AAAAA6FI4AgAAAKBL4QgAAACArt3bnQDAiezdf/1K0x05cNnEmQAAAJyenHEEAAAAQJfCEQAAAABdLlUDTisufwMAAFidM44AAAAA6FI4AgAAAKDLpWoAW7DqpW+Jy98AAID5ccYRAAAAAF3OOALYYdzAGwAA2CmccQQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAECXwhEAAAAAXbu3OwEAprd3//UrTXfkwGUTZwIAAMyJM44AAAAA6FI4AgAAAKBL4QgAAACALoUjAAAAALoUjgAAAADo8lQ1ADZt1ae0JZ7UBgAAc+aMIwAAAAC6FI4AAAAA6FI4AgAAAKBL4QgAAACALoUjAAAAALpWKhxV1SVVdVtV3V5V+zvjq6peP4y/paqeNgx/SlXdvPT6TFW9Yhj3Y1X18aVxl47aMgAAAAC2ZPfJJqiqXUnekORZSY4mubGqDrbWPrQ02bOTnD+8np7kjUme3lq7LcmFS3E+nuQdS/P9VGvttSO0AwAAAICRrXLG0cVJbm+t3dFauy/JW5Ps2zDNviRvbgvvTfKYqjprwzTPTPKXrbWPbDlrAAAAACa3SuHo7CQfW/p8dBi22WkuT/KWDcOuGi5tu7aqHtv78qq6sqoOV9XhY8eOrZAuAAAAAGNYpXBUnWFtM9NU1RlJvjvJry+Nf2OSJ2dxKdtdSV7X+/LW2jWttYtaaxft2bNnhXQBAAAAGMMqhaOjSc5d+nxOkjs3Oc2zk9zUWrv7+IDW2t2ttS+01h5I8vNZXBIHAAAAwA6xSuHoxiTnV9V5w5lDlyc5uGGag0mePzxd7VuS/G1r7a6l8c/LhsvUNtwD6XuSfHDT2QMAAAAwmZM+Va21dn9VXZXkXUl2Jbm2tXZrVb10GH91kkNJLk1ye5J7k7zo+PxV9cgsnsj2kg2hX1NVF2ZxSduRzngAAAAAttFJC0dJ0lo7lEVxaHnY1UvvW5KXnWDee5M8vjP8ik1lCgAAAMDDapVL1QAAAAA4DSkcAQAAANClcAQAAABAl8IRAAAAAF0r3RwbAKa2d//1K0135MBlE2cCAAAc54wjAAAAALoUjgAAAADoUjgCAAAAoEvhCAAAAIAuN8cG4JTlhtsAALA1zjgCAAAAoEvhCAAAAIAuhSMAAAAAuhSOAAAAAOhyc2wAWNGqN9tO3HAbAIBTgzOOAAAAAOhSOAIAAACgy6VqALCNVr38zaVvAABsB4UjADjFKEYBADAWl6oBAAAA0KVwBAAAAECXwhEAAAAAXQpHAAAAAHS5OTYA8JBWvdl24obbAACnGmccAQAAANClcAQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAECXwhEAAAAAXQpHAAAAAHQpHAEAAADQpXAEAAAAQJfCEQAAAABdCkcAAAAAdCkcAQAAANClcAQAAABA1+7tTgAAOP3s3X/9StMdOXDZxJkAAPBQnHEEAAAAQJfCEQAAAABdK12qVlWXJPmZJLuSvKm1dmDD+BrGX5rk3iQvbK3dNIw7kuSzSb6Q5P7W2kXD8Mcl+S9J9iY5kuT7Wmuf3nKLAIDTksvfAADGd9LCUVXtSvKGJM9KcjTJjVV1sLX2oaXJnp3k/OH19CRvHP4e952ttU9uCL0/yQ2ttQNVtX/4/Kq1WwIAMKJVC1GJYhQAcOpa5VK1i5Pc3lq7o7V2X5K3Jtm3YZp9Sd7cFt6b5DFVddZJ4u5Lct3w/rokz1k9bQAAAACmtkrh6OwkH1v6fHQYtuo0LcnvVtX7qurKpWme2Fq7K0mGv1/d+/KqurKqDlfV4WPHjq2QLgAAAABjWKVwVJ1hbRPTfGtr7WlZXM72sqr69k3kl9baNa21i1prF+3Zs2czswIAAACwBavcHPtoknOXPp+T5M5Vp2mtHf97T1W9I4tL3/4wyd1VdVZr7a7hsrZ71msCAMA8uIE3ADA3q5xxdGOS86vqvKo6I8nlSQ5umOZgkufXwrck+duhIPQVVfWoJKmqr0jyXUk+uDTPC4b3L0jyzi22BQAAAIARnfSMo9ba/VV1VZJ3JdmV5NrW2q1V9dJh/NVJDiW5NMntSe5N8qJh9icmeUdVHf+uX2ut/c4w7kCSt1XVi5N8NMlzR2sVAAAAAFu2yqVqaa0dyqI4tDzs6qX3LcnLOvPdkeSpJ4j5qSTP3EyyAAAAADx8VrlUDQAAAIDT0EpnHAEAsDO54TYAMCWFIwAA/s6qhahEMQoATgcKRwAATMpZUQAwX+5xBAAAAECXwhEAAAAAXS5VAwBgdsa+/M29nQCgzxlHAAAAAHQpHAEAAADQpXAEAAAAQJfCEQAAAABdCkcAAAAAdCkcAQAAANClcAQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAECXwhEAAAAAXbu3OwEAADgV7d1//UrTHTlw2cSZAMD6nHEEAAAAQJfCEQAAAABdCkcAAAAAdCkcAQAAANClcAQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAECXwhEAAAAAXbu3OwEAAGA1e/dfv9J0Rw5cNnEmAJwunHEEAAAAQJczjgAA4DS16hlMibOYAE5XCkcAAMBoXE4HcGpROAIAAHY0xSiA7eMeRwAAAAB0KRwBAAAA0KVwBAAAAECXwhEAAAAAXW6ODQAAnFZWvdl24obbAApHAAAAW+TJb8CpyqVqAAAAAHStdMZRVV2S5GeS7EryptbagQ3jaxh/aZJ7k7ywtXZTVZ2b5M1JzkzyQJJrWms/M8zzY0n+TZJjQ5hXt9YObblFAAAApwBnMQE7wUkLR1W1K8kbkjwrydEkN1bVwdbah5Yme3aS84fX05O8cfh7f5J/NxSRHpXkfVX17qV5f6q19trxmgMAAADAWFY54+jiJLe31u5Ikqp6a5J9SZYLR/uSvLm11pK8t6oeU1VntdbuSnJXkrTWPltVH05y9oZ5AQAAmNgUNwV3VhSc+lYpHJ2d5GNLn49mcTbRyaY5O0PRKEmqam+Sb0zyJ0vTXVVVz09yOIszkz698cur6sokVybJk570pBXSBQAAYK4Uo2BnWeXm2NUZ1jYzTVV9ZZLfSPKK1tpnhsFvTPLkJBdmUWB6Xe/LW2vXtNYuaq1dtGfPnhXSBQAAAGAMqxSOjiY5d+nzOUnuXHWaqnpEFkWjX22tvf34BK21u1trX2itPZDk57O4JA4AAACAHWKVwtGNSc6vqvOq6owklyc5uGGag0meXwvfkuRvW2t3DU9b+4UkH26t/eTyDFV11tLH70nywbVbAQAAAMDoTnqPo9ba/VV1VZJ3JdmV5NrW2q1V9dJh/NVJDiW5NMntSe5N8qJh9m9NckWSD1TVzcOwV7fWDiV5TVVdmMUlbUeSvGSkNgEAAECSaW4KDqeTVW6OnaHQc2jDsKuX3rckL+vM90fp3/8orbUrNpUpAAAAAA+rVS5VAwAAAOA0pHAEAAAAQJfCEQAAAABdCkcAAAAAdCkcAQAAANClcAQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0LV7uxMAAACAOdm7//qVpjty4LKJM4HpOeMIAAAAgC6FIwAAAAC6FI4AAAAA6FI4AgAAAKBL4QgAAACALoUjAAAAALoUjgAAAADoUjgCAAAAoEvhCAAAAIAuhSMAAAAAunZvdwIAAABwutu7//qVpjty4LKJM4EvpnAEAAAAp5hVC1GJYhQPzaVqAAAAAHQ54wgAAAA4KZfTnZ6ccQQAAABAl8IRAAAAAF0KRwAAAAB0KRwBAAAA0KVwBAAAAECXp6oBAAAA28KT2nY+ZxwBAAAA0OWMIwAAAOCUsOoZTImzmFbljCMAAAAAuhSOAAAAAOhSOAIAAACgS+EIAAAAgC6FIwAAAAC6FI4AAAAA6FI4AgAAAKBr93YnAAAAALBT7d1//UrTHTlw2cSZbA9nHAEAAADQpXAEAAAAQNdKhaOquqSqbquq26tqf2d8VdXrh/G3VNXTTjZvVT2uqt5dVX8x/H3sOE0CAAAAYAwnLRxV1a4kb0jy7CQXJHleVV2wYbJnJzl/eF2Z5I0rzLs/yQ2ttfOT3DB8BgAAAGCHWOWMo4uT3N5au6O1dl+StybZt2GafUne3Bbem+QxVXXWSebdl+S64f11SZ6ztaYAAAAAMKZqrT30BFXfm+SS1toPDJ+vSPL01tpVS9P8VpIDrbU/Gj7fkORVSfaeaN6q+pvW2mOWYny6tfb3LlerqiuzOIspSZ6S5LYV2vWEJJ9cYbrNmEPMOeQ4Rcw55DhFzDnkOEXMOeQ4Rcw55DhFzDnkOEXMOeQ4Rcw55DhFzDnkOEXMOeQ4Rcw55DhFzDnkOEXMOeQ4Rcw55DhFzDnkOEXMOeQ4Rcw55LiZmF/TWtvTG7F7hZmrM2xjtelE06wy70NqrV2T5JrNzFNVh1trF21mnlMh5hxynCLmHHKcIuYccpwi5hxynCLmHHKcIuYccpwi5hxynCLmHHKcIuYccpwi5hxynCLmHHKcIuYccpwi5hxynCLmHHKcIuYccpwi5hxynCLmHHIcK+Yql6odTXLu0udzkty54jQPNe/dw+VsGf7es3raAAAAAExtlcLRjUnOr6rzquqMJJcnObhhmoNJnj88Xe1bkvxta+2uk8x7MMkLhvcvSPLOLbYFAAAAgBGd9FK11tr9VXVVkncl2ZXk2tbarVX10mH81UkOJbk0ye1J7k3yooeadwh9IMnbqurFST6a5LkjtmtTl7adQjHnkOMUMeeQ4xQx55DjFDHnkOMUMeeQ4xQx55DjFDHnkOMUMeeQ4xQx55DjFDHnkOMUMeeQ4xQx55DjFDHnkOMUMeeQ4xQx55DjFDHnkOMUMeeQ4ygxT3pzbAAAAABOT6tcqgYAAADAaUjhCAAAAIAuhSMAAAAAuhSOAAAAAOhSOGIyVfXdVfVl250HLKuqb6+qpwzv/0lVvbKqLtvuvDaqqjOr6szh/Z6q+hdV9Q9Hin3eEO/rx4jH1lXVV1bV91bVv62qH6qqS6pq7WN0VT26qp7cGf4NW8t0PFX1pOPHiFp4UVX9bFX9YFWd9Kmv262qnrXdOQDATlBVP7HdOTCt2ReOquqqqnrC8P7rquoPq+pvqupPquq/XyPerqp6SVX9eFV964Zx/3HNHL9h6f0jquo/VtXBqvqJqnrkmjEfWVX/oar+fVV9WVW9cIj5mqr6ynViPsR3rfv4vv+S5GhV/XJVXVpVu0bI5e1V9f1jt3HDd/z5FucftU8OcUZd31X1JVX1P1fV9VX1Z1X1vqp6a1V9xzr5DTGn6Odjb98/neRAkl+uqh9P8pokX57k31bV/7VmjqP3yap6SZL3JHlvVf1gkt9K8s+SvL2qXrxGvN9cer8vye8l+edJ3llVLxwj5w3ft9Y+Y+xlWVW7h/3571TVLUNf/+2qemlVPWIHxfy+JL+f5JIkVyW5OMkVSW5es59/X5L/N8lvVNWtVfXNS6N/ac0cR293kkN58HfIgSSXJfmTJN+cNR4bO8U+6CR+YZ2ZJlqWG79jq8ex0X9jVNXXVtW1VfW/16JQ+vNV9cGq+vWq2rtGvCn2vVP8Bhz7+L3jj7VDnLHX9+i/W07yfesex0btQ1O0e6KYk+9/R9ivjd7PT/J9oz5SfQt9ctRtcYj5+g2vn03yvxz/vEa80fe9J/ierfahsX+n7vhj7RfFbq1tZf5tV1W3ttb+4fD++iRvaq29Y9j5/R+ttW99qPk78d6U5JFJ/jSLH+5/0Fr7kWHcTa21p62R49/NV1WvS/L4JL+Y5DlJHt9ae/4aMd+W5GNZ/KP3KUk+nORtWfxj8MzW2hWbjPe4E41K8mettXPWyPH9SZ6R5HuTXJ7kHyV5R5K3tNb+YLPxhpgfz+If1M9I8v8keUuS61tr960Z77NJjm8ENfx9ZJJ7k7TW2qPXiDlqnxzijL2+fzHJR7JYht+b5DNJ/luSVyV5Z2vtZ9fIcYp+Pvb2fWsW/fDLk3w8ydmttXtr8Y+197fW/tEaOY7aJ4eYH0jy9CHPjyT5utbaJ6rqsUl+v7V24Sbjvb+19o3D+z9O8q9ba381/IC6obX21DVynGKfMfb2/ZYkf5PkuiRHh8HnJHlBkse11v7VDol5S5JvGfriE5L8amvtfxp+iF/dWvsfNhnv5iTPbq3dVVUXJ3lzkle31t6+3Bc2GXOKdn+otXbB8P59Sb65tfbA8PnPNtsvJ9oHHTzRqCTPaK19xRoxR12WEx3HRj3mDDH/MItt+quSfH8W6+ZtSb4ri33SMzYZb4p97xS/Acc+fu/4Y+0QZ+z1PcXvlimOY6P2oYnaveN/A87o9/mofWiiPjnqtjjEPJrkvyb53Ty4fl6b5JVJ0lq7bpPxptj3TtGHxv6duuOPtV+ktTbrV5Lblt7fuGHcLWvEu2Xp/e4s/tfz7Um+NIt/WK6T4/uX3t+c5BHD+1onx+NxlmJ8Ig8WAdeKmeQLSe5I8ldLr+Of71szx5s2fD4zycuz2OA+tpVlmeRRWexYDiU5NmwU37VGvJ/N4h9VT1wa9lc7qU9OtL5v2fD5vcPfL03y4a2sm+P5jtTPx96+Pzj8/bIkn07y5cPnXUk+tJV2j9Unh1g3Lb3/sxMt5zXj/elW4w3zTbHPGHVZLvefzrg/XzPHKWJ+YGmb/vIN29IH14j3wQ2fz0ryvmH/e9OaOU7R7ndlUXxJkt9I8jXD+8dv7Peb6T/D+7H2QZ/O4kyof7rh9R1J7t4JyzLTHMduXlp2Wz7mdNbPR080brPxRt73TvEbcNRlOVE/n+J3y9jre4rfLVMcx0btQxO1e8f/BpxovzZFPx+1D03UJ5fXzZa3xWG+RyX56SS/lsV/wibJHVtYN1Pse6foQ+9fav8Yv1NvHv7u2GPt8mv2l6ol+b+r6peq6muTvKOqXlGL+ya8KMlH14h3xvE3rbX7W2tXZrED/L0k656W9lVV9T1V9S+TfGlr7fND/JYHK6FrGWIcGv5uJeYdSb6jtXbe0utrW2vnJbl7zfRq+UNr7ROttde31v5xkn+yZszj7fxsa+2XW2uXZlGh/ZMk+zcdrLUfSvIzSd5SVS+vxT1FtrROMn6fXM53rPX9+Rruf1JVT0ty3xDvc2vGS6bp52Mvy+ur6o+y+J+1NyV5W1X9r0l+J8laZ8Fl5D45eKAevGTl7+6/VIv7wayz335qVX1m+N+XC+vBeyedkUXRbB1T7DPGXpafrqrn1tK9gmpxiv6/yqIgsI4pYh5K8jtV9eos/vfu14e4j8uG/eiKPlNL9zdqrd2VRaFjX5J175M1Rbt/IMmPDv87dkYWl+b9Xhb/i/cja8SbYh/03iT3ttb+YMPrvya5bc2Yoy7LiY5jx2OPdcxJFvu1/64Wl04+sqouShaXjGS9/dAU+94pfgMejzfWspzDsTYZf31P8btliuPY2H1oinbv+N+AM/p9PnYfmqJPjr0tHt/vviLJ65L8SlW9Mlu7Bc7o+96J+tAUx52dfqz9okRn/0rywixW2CeTfDbJh5L8RJKvWiPWryS5pDP8B5J8fs38fnHD64nD8DOzuExknZhvSvKVneFPTvJHa8R7WZKnnmDcD62Z4xUPMe7b1oz5hxP1oS/J4n/j/1uSO0eIN1qfnGh9PyOLg+SfZ/G/GE8fhu9J8po1cxy9n4+9LJOcm+QfZ3FZ0PHl98ok37eT+uSQ5+7O8LOT/Oga8Z50guFftYV2T7HPGHVZJtmbxb3Wjg19/c+T3DMMO28HxTw3yaVDX3zW0vBaZ/0k+bYsLm/cOPwRSf7TSO3+izHaPfz9B1kUtf5lFpdofsma7Z7iWHvuQy3nnbIsh7ijHccy8jFnmPeZWRTbPpzFfx79RpLbh7bvWyPeFPveKX4Djn383vHH2onW9xS/W6Y4jo3ahyZq95x+A+703+ej9qGJ+uSo2+IQ89yl9zXk/SvD53WO36Pve6foQxn/d+qOP9Yuv2Z/jyP+vqqqtgNWbFXdkeTqJD/ZWrt/GPbELKrTT2mtffNDzb8dquqsJN/YWju03bmsat31XVWVxXXnn5wgrR1pLn1y7Dzn0u4pVdXjszgFeLT+PlbMYf385ySvG3F9jxavE3/Mdu/ofjl1jhP1y0mPY2P+xqjFPb0+3Vr7whjx5man/F57uGx1fZ+Ov1uSado9t2U5x9/nO9kI22Lv2HhmFvc52hHH743m1od24rH2VLhU7YvUyI+ZHjvewxFz3U5W4z+++WlZVEzfX1XPqKofzuKmZ+/J4n+Vt2yMZbnc7tbaXcd3KFto90N919qPbz7R+kmy1pMg2sLf+8EwRY5bWZYjx/ymJF+bkfvkBO3+poy77Ywd7yFtpQ+NHfP4ummtfWq5v4+xfXdirtvub0pyXsZd32PG+yKttU8ledQIx7HJ+2Vt/fHAk+RYVWdW1ZnDsqxhWa57GeFGX5bky8b8jZE8uCzHLHS01j7ZWvvCFrbvM+vBS2/3jLwcN37X6Pu1JP/jmMHGzHGEbefvHRuX1ve6+99HZXGm7Mbv2cpvjMn70FaX5cbfa2OsmyRPzOJeMqO1e8plueH3+VZ+p066vif6N94Uj7n/kS0WEXrHxvdmC8fGKf4NsawtLttf91YpJ7TV9XOiPrmVY+3GmEm+PYtL6rZmK6cr7YRXkt9cer8vi1MufzGL0y9fOGK829aJN5eYWVyqc2cW15PemsXTbY6PW+tmqkvz/3CSB7J4esw5E63vHdfuE3zfR9ec72HLcyflOFW7R+6Ts9h2pog3dh8aO+Zctu85rO+H2PeudaydIs8kr9/w+tksnl72+iSv3wk5DrFeMiy/I0l+MIvLJq4djmMvHnHdbOU3xmTL8gTft872PepynCLHhzvmuvGmWN9j73+n2J9P0YfGXpYTrZsp2v2wbY9b6OdTtPs3l96P8e+SKdb3jj82TrR97/hlObdtcXfm72uW3r8qiye0/N1jppP80jbHm0vMVyf5pvbg45t/uape3Vp7e9a7OWuq6jFJ/s8sKs+XZHEPj9+uqh9urf3eOjEzj3Y/1OObH79OzLHznEOOU8ScqE/u+G1ninZP0YcmiDmL7XsO6zsTHMcmyPNf5O8/HvjyLJ4ot5aJluVVWdyk/MuzeCT217XWPlFVj03y+0l+YZPxpviNMcWyHHvbGXs5zmK/NtHxe/T1nfH3v1P8xhi9D2X8ZTnFupmi3aPGnKifT9Husfe/U6zvORwbp9i+57Asd/y2uOxUKBy1pfe7W2t/lSxOh62qB3ZAvLnE3N0Wp/CltfanVfWdSX6rqs7J+nd1vynJzyV5WVtc//q7VXVhkp+rqo+01p63Rsw5tPvbknx/kv9vw/BKcvGaMcfOcw45ThFzij45h21ninZP0YfGjjmX7XsO63uK49jYef6DJD+exY/Yf99a+3hV/W+ttevWzG+KHJPFjT7vTXJvVf1la+0TSdJa+3RVrdMvp1g3UyzLsbedsZfjFDlOEXOKHKdY32Pvf6fYn0/Rh8ZellOsmynaPXbMKfr5FO0ee/87xfqew7Fxiu17DstyDtvig9oWTlfaCa8kX0jymSzujH9fkjOH4WckuWW7480lZpI/TvLkDcMelUW1/HNr5njCUxaT/JtTuN2/neQ7TzBurbvxj53nHHKcqN1T9Mkdv+1M1O4p+tCoMWe0fc9hfU9xHBs9z2Heb8rif9VemeTIunEmXJaHkzxiY/ws7k30Zzth3Uy0LMfevkddjlPkOFG7R89xovU99vF7iv356H1oimU5wbqZYtsZe782xbY4Rbsn2f+O3X8m6ENj/24Zffuew7Kcw7b4RbHHWHjb+crIj5keO95cYmaCxzfPZH1P8djqKR7fPGqec8hxqphjv+aQ40TtnqIPjRpzLtv3HF5THMcmyHHUxwNPmWcW/7u6cfjZSX50J6ybKZblBNv3qMtxihynaveUOY64vsf+3TLJ/nzKPjTGspxqW5yi3SPv1ybp5xO0e+x/l0y6792px8aptu+dviznsC1+UYzt7ihbfSW5I8l/WF5AWTwp4FeS3Ljd8eYSc4j3qjFznNH6HrXdE67v0fKcQ45z6ZdzyHHCdp92+7Up2j2H1xzafYIcz9xJOU6xLB/GbXFLy3LG7d5RMWe2vsf+3bLj9+djL8s5bItTxJxDjg9ju6dY3zvq2Pgwbt87alnOoU8uv74k8zeHx1bPIeakj28e0RzaPdX6Hvtx3Ts9x6lijm0OOU7hdN2vTf4I+R1qDu0e/fHAE5nr75atLsu5tnunxZzT+h77d8sc9udjL8s5bItTxJxDjlPEfLjW9047Nj5c2/dOW5Zz6JMP2u4K44iVyh/ODn2M8ZxiTpGj9b1zY84hx6lijv2aQ45zaffp2s/n8JpDu+eQ4xR5zqWfa7d276R4c4k5hxy1+/Rr99ivubT7dF3f295BRlgoj0nyn5PcnOS7kvx0kg9k8TjEbY83l5hT5Gh979yYc8hxLv1yDjnOpd2naz+fw2sO7Z5DjlPkOZd+rt3ard3bH28uMeeQ4+nc7rFfc2n36b6+t72jjNDR7sjijubL1/FdmMXd2d+y3fHmEnOKHK3vnRtzDjnOpV/OIce5tPt07edzeM2h3XPIcYo859LPtVu7tVu7T6UcT+d2j/2aS7tP9/W97R1lhI42h8cY7/iYU+Rofe/cmHPIcaqYY7/mkONc2n269vM5vObQ7jnkOEWec+nn2q3d2q3dp1KOp3O7x37Npd2n+/quIQgAAAAAfJFT4alqAAAAAExA4QgAAACALoUjAAAAALoUjgAAAADo+v8BgoD32ZfBHq4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's plot the ordered mutual_info values per feature\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(20, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3128, 54) (782, 54) (3128,) (782,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No we Will select the  top 15 important features\n",
    "sel_15_cols = SelectKBest(mutual_info_classif, k=15)\n",
    "sel_15_cols.fit(X_train, y_train)\n",
    "cols=X_train.columns[sel_15_cols.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X5', 'X7', 'X16', 'X17', 'X19', 'X21', 'X23', 'X24', 'X25', 'X27',\n",
       "       'X52', 'X53', 'X55', 'X56', 'X57'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train[['X3', 'X5', 'X7', 'X16', 'X19', 'X21', 'X23', 'X24', 'X25', 'X27',\n",
    "       'X52', 'X53', 'X55', 'X56', 'X57']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test[['X3', 'X5', 'X7', 'X16', 'X19', 'X21', 'X23', 'X24', 'X25', 'X27',\n",
    "       'X52', 'X53', 'X55', 'X56', 'X57']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=LogisticRegression()\n",
    "\n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "x_pred = lm.predict(X_train)\n",
    "\n",
    "x_pred_prob=lm.predict_proba(X_train)\n",
    "y_pred=lm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91       475\n",
      "           1       0.90      0.79      0.84       307\n",
      "\n",
      "    accuracy                           0.88       782\n",
      "   macro avg       0.88      0.86      0.87       782\n",
      "weighted avg       0.88      0.88      0.88       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Score : 0.881\n",
      "Accuracy : 0.881\n",
      "\n",
      "Recall : 0.788\n",
      "Precission : 0.896\n",
      "\n",
      "AUC : 0.953\n",
      "F-Beta Score : 0.808\n"
     ]
    }
   ],
   "source": [
    "y_pred     = lm.predict(X_test)\n",
    "y_pred_prob= lm.predict_proba(X_test)\n",
    "print('Test Data Score : {0:.3f}'.format(lm.score(X_test, y_test)))\n",
    "\n",
    "print('Accuracy : {0:.3f}'.format(mt.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('\\nRecall : {0:.3f}'.format(mt.recall_score(y_test, y_pred)))\n",
    "print('Precission : {0:.3f}'.format(mt.precision_score(y_test, y_pred)))\n",
    "\n",
    "print('\\nAUC : {0:.3f}'.format(mt.roc_auc_score(y_test, y_pred_prob[:,1]) ))\n",
    "print('F-Beta Score : {0:.3f}'.format(mt.fbeta_score(y_test, y_pred, beta=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "x_pred = model.predict(X_train)\n",
    "\n",
    "x_pred_prob=model.predict_proba(X_train)\n",
    "\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Score : 0.948\n",
      "Accuracy : 0.948\n",
      "\n",
      "Recall : 0.928\n",
      "Precission : 0.938\n",
      "\n",
      "AUC : 0.987\n",
      "F-Beta Score : 0.933\n"
     ]
    }
   ],
   "source": [
    "y_pred     = model.predict(X_test)\n",
    "y_pred_prob= model.predict_proba(X_test)\n",
    "print('Test Data Score : {0:.3f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "print('Accuracy : {0:.3f}'.format(mt.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('\\nRecall : {0:.3f}'.format(mt.recall_score(y_test, y_pred)))\n",
    "print('Precission : {0:.3f}'.format(mt.precision_score(y_test, y_pred)))\n",
    "\n",
    "print('\\nAUC : {0:.3f}'.format(mt.roc_auc_score(y_test, y_pred_prob[:,1]) ))\n",
    "print('F-Beta Score : {0:.3f}'.format(mt.fbeta_score(y_test, y_pred, beta=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       475\n",
      "           1       0.94      0.93      0.93       307\n",
      "\n",
      "    accuracy                           0.95       782\n",
      "   macro avg       0.95      0.94      0.94       782\n",
      "weighted avg       0.95      0.95      0.95       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96485623, 0.93290735, 0.93610224, 0.96485623, 0.92971246,\n",
       "       0.92332268, 0.9456869 , 0.94249201, 0.94871795, 0.94230769])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92405063, 0.91139241, 0.94871795, 0.93589744, 0.96153846,\n",
       "       0.96153846, 0.91025641, 0.93589744, 0.91025641, 0.88461538])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X_test,y_test,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda folder\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "x_pred3 = xgb.predict(X_train)\n",
    "x_pred_prob3= xgb.predict_proba(X_train)\n",
    "y_pred3 = xgb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       475\n",
      "           1       0.91      0.92      0.91       307\n",
      "\n",
      "    accuracy                           0.93       782\n",
      "   macro avg       0.93      0.93      0.93       782\n",
      "weighted avg       0.93      0.93      0.93       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Score : 0.948\n",
      "Accuracy : 0.932\n",
      "\n",
      "Recall : 0.919\n",
      "Precission : 0.910\n",
      "\n",
      "AUC : 0.982\n",
      "F-Beta Score : 0.917\n"
     ]
    }
   ],
   "source": [
    "y_pred3     = xgb.predict(X_test)\n",
    "y_pred_prob3= xgb.predict_proba(X_test)\n",
    "print('Test Data Score : {0:.3f}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "print('Accuracy : {0:.3f}'.format(mt.accuracy_score(y_test, y_pred3)))\n",
    "\n",
    "print('\\nRecall : {0:.3f}'.format(mt.recall_score(y_test, y_pred3)))\n",
    "print('Precission : {0:.3f}'.format(mt.precision_score(y_test, y_pred3)))\n",
    "\n",
    "print('\\nAUC : {0:.3f}'.format(mt.roc_auc_score(y_test, y_pred_prob3[:,1]) ))\n",
    "print('F-Beta Score : {0:.3f}'.format(mt.fbeta_score(y_test, y_pred3, beta=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X48</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "      <th>X51</th>\n",
       "      <th>X52</th>\n",
       "      <th>X53</th>\n",
       "      <th>X54</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.342</td>\n",
       "      <td>47</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.375</td>\n",
       "      <td>168</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   X1   X2    X3   X4    X5   X6    X7   X8   X9  ...  X48  X49  \\\n",
       "0           0  0.7  0.0  0.70  0.0  0.00  0.0  0.00  0.0  0.0  ...  0.0  0.0   \n",
       "1           1  0.0  0.0  0.84  0.0  0.84  0.0  0.84  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "     X50  X51    X52    X53  X54     X55  X56  X57  \n",
       "0  0.000  0.0  0.105  0.000  0.0   2.342   47   89  \n",
       "1  0.388  0.0  0.776  0.129  0.0  10.375  168  249  \n",
       "\n",
       "[2 rows x 58 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= test_data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=test_data[['X3', 'X5', 'X7', 'X16', 'X19', 'X21', 'X23', 'X24', 'X25', 'X27',\n",
    "       'X52', 'X53', 'X55', 'X56', 'X57']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_pred = pd.DataFrame(model.predict(test_data), columns=['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_pred.to_csv('test_data_pred.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred\n",
       "0       479\n",
       "1       212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_pred.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model predictions for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred\n",
       "0       0\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "..    ...\n",
       "686     0\n",
       "687     0\n",
       "688     0\n",
       "689     0\n",
       "690     0\n",
       "\n",
       "[691 rows x 1 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
